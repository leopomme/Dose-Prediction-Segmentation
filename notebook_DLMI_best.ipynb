{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport h5py\n\nimport cv2\nimport albumentations as A\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom albumentations.pytorch import ToTensorV2\n\nimport time \nfrom tqdm import tqdm\nfrom glob import glob\nimport zipfile\nimport shutil\n","metadata":{"id":"59xiuIQZLCPP","execution":{"iopub.status.busy":"2023-03-21T10:43:48.679408Z","iopub.execute_input":"2023-03-21T10:43:48.680371Z","iopub.status.idle":"2023-03-21T10:43:48.689246Z","shell.execute_reply.started":"2023-03-21T10:43:48.680313Z","shell.execute_reply":"2023-03-21T10:43:48.688176Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/soniamartinot/MVA-Dose-Prediction.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LHRC5fH0LKcf","outputId":"b8b6e02b-bc8b-49d6-ffe1-565a7bddf4fb","execution":{"iopub.status.busy":"2023-03-21T10:43:48.693456Z","iopub.execute_input":"2023-03-21T10:43:48.693731Z","iopub.status.idle":"2023-03-21T10:43:49.671982Z","shell.execute_reply.started":"2023-03-21T10:43:48.693705Z","shell.execute_reply":"2023-03-21T10:43:49.670718Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"fatal: destination path 'MVA-Dose-Prediction' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"e7i8LGHsqgeA","execution":{"iopub.status.busy":"2023-03-21T10:43:49.674593Z","iopub.execute_input":"2023-03-21T10:43:49.675558Z","iopub.status.idle":"2023-03-21T10:43:49.680446Z","shell.execute_reply.started":"2023-03-21T10:43:49.675519Z","shell.execute_reply":"2023-03-21T10:43:49.679094Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"transform_img = A.Compose([\n    A.GaussNoise(var_limit=(10, 50), p=0.25),\n#     A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),\n    A.Blur(blur_limit=(3, 7), p=0.25),\n])\n\ntransform_img_mask = A.Compose([\n    A.ElasticTransform(alpha=15, sigma=5, alpha_affine=5, p=0.25),\n    A.Rotate(limit=10, p=0.25),\n])\n\ntrain_transforms = {\n    'img': transform_img,\n    'img_mask': transform_img_mask\n}\n\nval_transforms = None\n\n","metadata":{"id":"k7TofpC37Fah","execution":{"iopub.status.busy":"2023-03-21T10:43:49.682103Z","iopub.execute_input":"2023-03-21T10:43:49.682637Z","iopub.status.idle":"2023-03-21T10:43:49.692511Z","shell.execute_reply.started":"2023-03-21T10:43:49.682600Z","shell.execute_reply":"2023-03-21T10:43:49.691512Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"class DoseDataset(torch.utils.data.Dataset):\n    def __init__(self, data_path, transform=None):\n        self.data_path = data_path\n        self.samples = os.listdir(data_path)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        sample_path = self.data_path + os.sep + self.samples[idx]\n        ct_scan = np.load(sample_path + os.sep + 'ct.npy')\n        possible_dose_mask = np.load(sample_path + os.sep + 'possible_dose_mask.npy')\n        dose = torch.from_numpy(np.load(sample_path + os.sep + 'dose.npy')).float()\n        structure_masks = np.load(sample_path + os.sep + 'structure_masks.npy')\n\n        combined_masks = [possible_dose_mask] + [structure_masks[i] for i in range(structure_masks.shape[0])]\n\n        if self.transform:\n            if 'img_mask' in self.transform:\n                transform_func = self.transform['img_mask']\n                augmentations = transform_func(image=ct_scan, masks=combined_masks)\n                ct_scan = augmentations['image']\n                combined_masks = augmentations['masks']\n            if 'img' in self.transform:\n                transform_func = self.transform['img']\n                augmentations = transform_func(image=ct_scan)\n                ct_scan = augmentations['image']\n        \n        # Convert NumPy arrays to PyTorch tensors\n        ct_scan_tensor = torch.from_numpy(ct_scan).float().unsqueeze(0)\n        combined_masks_tensor = torch.from_numpy(np.stack(combined_masks, axis=0)).float()\n\n        # Normalize the ct_scan tensor\n        mean = ct_scan_tensor.mean()\n        std = ct_scan_tensor.std()\n        normalize = transforms.Normalize(mean=[mean], std=[std+1e-6])\n        ct_scan_tensor = normalize(ct_scan_tensor)\n\n        # Combine ct_scan_tensor and combined_masks_tensor\n        input_image = torch.cat([ct_scan_tensor, combined_masks_tensor], dim=0)\n        dose = dose.unsqueeze(0)\n\n        return {'input_image': input_image, 'dose': dose}","metadata":{"id":"oACxne0dLMio","execution":{"iopub.status.busy":"2023-03-21T10:43:49.695490Z","iopub.execute_input":"2023-03-21T10:43:49.696021Z","iopub.status.idle":"2023-03-21T10:43:49.710656Z","shell.execute_reply.started":"2023-03-21T10:43:49.695980Z","shell.execute_reply":"2023-03-21T10:43:49.709546Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"class test_DoseDataset(torch.utils.data.Dataset):\n    def __init__(self, data_path, transform=None):\n        self.data_path = data_path\n        self.samples = os.listdir(data_path)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        sample_path = self.data_path + os.sep + self.samples[idx]\n        ct_scan = torch.from_numpy(np.load(sample_path + os.sep + 'ct.npy')).float()\n        possible_dose_mask = torch.from_numpy(np.load(sample_path + os.sep + 'possible_dose_mask.npy')).float()\n        structure_masks = torch.from_numpy(np.load(sample_path + os.sep + 'structure_masks.npy')).float()\n\n        input_image = np.concatenate([ct_scan[np.newaxis, :, :], possible_dose_mask[np.newaxis, :, :], structure_masks], axis=0)\n        input_image = torch.tensor(input_image, dtype=torch.float32)\n        \n        return {'sample_name': self.samples[idx], 'input_image': input_image}","metadata":{"id":"-w3tDPXwh4J3","execution":{"iopub.status.busy":"2023-03-21T10:43:49.713161Z","iopub.execute_input":"2023-03-21T10:43:49.713834Z","iopub.status.idle":"2023-03-21T10:43:49.724806Z","shell.execute_reply.started":"2023-03-21T10:43:49.713797Z","shell.execute_reply":"2023-03-21T10:43:49.723790Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"train_dir = \"./MVA-Dose-Prediction/train/\"\n\ntrain_dataset = DoseDataset(train_dir, transform=train_transforms)\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, num_workers=2, shuffle=True, pin_memory=True)\nprint(len(train_dataloader))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Z-Xm8dNLZPG","outputId":"b178e04d-c119-4969-88c2-f68574f76e58","execution":{"iopub.status.busy":"2023-03-21T10:43:49.727404Z","iopub.execute_input":"2023-03-21T10:43:49.727679Z","iopub.status.idle":"2023-03-21T10:43:49.745676Z","shell.execute_reply.started":"2023-03-21T10:43:49.727649Z","shell.execute_reply":"2023-03-21T10:43:49.744425Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"244\n","output_type":"stream"}]},{"cell_type":"code","source":"val_dir = \"./MVA-Dose-Prediction/validation/\"\n\nval_dataset = DoseDataset(val_dir, transform=val_transforms)\nval_dataloader = DataLoader(val_dataset, batch_size=32, num_workers=2, shuffle=True, pin_memory=True)\nprint(len(val_dataloader))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gdAO-FbeNTnJ","outputId":"23f97c42-233d-48a2-d320-d8c84b3c4b86","execution":{"iopub.status.busy":"2023-03-21T10:43:49.747729Z","iopub.execute_input":"2023-03-21T10:43:49.748195Z","iopub.status.idle":"2023-03-21T10:43:49.755491Z","shell.execute_reply.started":"2023-03-21T10:43:49.748158Z","shell.execute_reply":"2023-03-21T10:43:49.754235Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"38\n","output_type":"stream"}]},{"cell_type":"code","source":"test_dir = \"./MVA-Dose-Prediction/test\"\n\ntest_dataset = test_DoseDataset(test_dir)\ntest_dataloader = DataLoader(test_dataset, batch_size=32, num_workers=2, shuffle=True, pin_memory=True)\nprint(len(test_dataloader))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wyoQdyP3YxXo","outputId":"f7549a92-b457-4650-b482-6a3501a244df","execution":{"iopub.status.busy":"2023-03-21T10:43:49.757641Z","iopub.execute_input":"2023-03-21T10:43:49.758080Z","iopub.status.idle":"2023-03-21T10:43:49.766620Z","shell.execute_reply.started":"2023-03-21T10:43:49.758040Z","shell.execute_reply":"2023-03-21T10:43:49.765506Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"38\n","output_type":"stream"}]},{"cell_type":"code","source":"class DepthwiseSeparableConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=True):\n        super(DepthwiseSeparableConv, self).__init__()\n        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=in_channels, bias=False)\n        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=bias)\n\n    def forward(self, x):\n        x = self.depthwise(x)\n        x = self.pointwise(x)\n        return x\n","metadata":{"id":"sNEQKzsULCPf","execution":{"iopub.status.busy":"2023-03-21T10:43:49.768708Z","iopub.execute_input":"2023-03-21T10:43:49.769081Z","iopub.status.idle":"2023-03-21T10:43:49.778558Z","shell.execute_reply.started":"2023-03-21T10:43:49.769045Z","shell.execute_reply":"2023-03-21T10:43:49.777501Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"class DilatedConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=True):\n        super(DilatedConv, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias)\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n","metadata":{"id":"gVvJFgxkLCPf","execution":{"iopub.status.busy":"2023-03-21T10:43:49.782821Z","iopub.execute_input":"2023-03-21T10:43:49.783142Z","iopub.status.idle":"2023-03-21T10:43:49.792608Z","shell.execute_reply.started":"2023-03-21T10:43:49.783115Z","shell.execute_reply":"2023-03-21T10:43:49.791580Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"class DepthwiseSeparableDilatedConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=True):\n        super(DepthwiseSeparableDilatedConv, self).__init__()\n        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=in_channels, bias=False)\n        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=bias)\n\n    def forward(self, x):\n        x = self.depthwise(x)\n        x = self.pointwise(x)\n        return x\n","metadata":{"id":"bN--DiefLCPg","execution":{"iopub.status.busy":"2023-03-21T10:43:49.794328Z","iopub.execute_input":"2023-03-21T10:43:49.794674Z","iopub.status.idle":"2023-03-21T10:43:49.805055Z","shell.execute_reply.started":"2023-03-21T10:43:49.794640Z","shell.execute_reply":"2023-03-21T10:43:49.804125Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    def __init__(self, in_channels: int, forward_expansion: int, out_channels: int):\n        super(BasicBlock, self).__init__()\n        \"\"\"\n        A convolutional block with batch normalization and ReLU activation.\n        \"\"\"\n        self.conv1 = nn.Conv2d(in_channels, forward_expansion, kernel_size=3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(forward_expansion)\n        self.conv2 = nn.Conv2d(forward_expansion, out_channels, kernel_size=3, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = nn.ReLU()(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = nn.ReLU()(out)\n        return out\n\nclass BasicBlock_skip(nn.Module):\n    def __init__(self, in_channels: int, forward_expansion: int, out_channels: int):\n        super(BasicBlock_skip, self).__init__()\n\n        self.conv1 = nn.Conv2d(in_channels, forward_expansion, kernel_size=3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(forward_expansion)\n        self.conv2 = nn.Conv2d(forward_expansion, out_channels, kernel_size=3, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.residual = nn.Identity()\n        if in_channels != out_channels:\n            self.residual = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n                nn.BatchNorm2d(out_channels)\n            )\n\n    def forward(self, x):\n        identity = self.residual(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = nn.ReLU()(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        out += identity\n        out = nn.ReLU()(out)\n\n        return out\n\nclass BasicBlock_DSDC(nn.Module):\n    def __init__(self, in_channels: int, forward_expansion: int, out_channels: int, dilation=1):\n        super(BasicBlock_DSDC, self).__init__()\n\n        self.conv1 = DepthwiseSeparableDilatedConv(in_channels, forward_expansion, kernel_size=3, stride=1, padding=dilation, dilation=dilation)\n        self.bn1 = nn.BatchNorm2d(forward_expansion)\n        self.conv2 = DepthwiseSeparableDilatedConv(forward_expansion, out_channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.residual = nn.Identity()\n        if in_channels != out_channels:\n            self.residual = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n                nn.BatchNorm2d(out_channels)\n            )\n\n    def forward(self, x):\n        identity = self.residual(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = nn.ReLU()(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        out += identity\n        out = nn.ReLU()(out)\n\n        return out\n\n\nclass UNet(nn.Module):\n    def __init__(self, in_channels=12, out_channels=1):\n        super(UNet, self).__init__()\n\n        # Downward pass\n        self.down1 = nn.Sequential(\n            BasicBlock_DSDC(in_channels, 16, 16),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.down2 = nn.Sequential(\n            BasicBlock_DSDC(16, 32, 32),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.down3 = nn.Sequential(\n            BasicBlock_DSDC(32, 64, 64),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.down4 = nn.Sequential(\n            BasicBlock_DSDC(64, 128, 128),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n        # Bottom block\n        self.bottom = BasicBlock_DSDC(128, 256, 128)\n\n        # Upward pass\n        self.up4 = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n            nn.BatchNorm2d(64),\n            nn.ReLU()\n        )\n        self.up3 = nn.Sequential(\n            nn.ConvTranspose2d(64 + 64, 32, kernel_size=2, stride=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU()\n        )\n        self.up2 = nn.Sequential(\n            nn.ConvTranspose2d(32 + 32, 16, kernel_size=2, stride=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU()\n        )\n        self.up1 = nn.Sequential(\n            nn.ConvTranspose2d(16 + 16, out_channels, kernel_size=2, stride=2),\n            nn.BatchNorm2d(out_channels),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        # Downward pass\n        x1 = self.down1(x)\n        x2 = self.down2(x1)\n        x3 = self.down3(x2)\n        x4 = self.down4(x3)\n\n        # Bottom block\n        bottom = self.bottom(x4)\n\n        # Upward pass\n        y4 = self.up4(bottom)\n        y3 = self.up3(torch.cat((y4, x3), dim=1))\n        y2 = self.up2(torch.cat((y3, x2), dim=1))\n        y1 = self.up1(torch.cat((y2, x1), dim=1))\n\n        return y1\n\n","metadata":{"id":"s8jseKcRLCPc","execution":{"iopub.status.busy":"2023-03-21T10:43:49.806919Z","iopub.execute_input":"2023-03-21T10:43:49.807369Z","iopub.status.idle":"2023-03-21T10:43:49.833894Z","shell.execute_reply.started":"2023-03-21T10:43:49.807330Z","shell.execute_reply":"2023-03-21T10:43:49.833024Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"class BigBasicBlock(nn.Module):\n    def __init__(self, in_channels: int, forward_expansion: int, out_channels: int):\n        super(BigBasicBlock, self).__init__()\n \n        self.conv1 = nn.Conv2d(in_channels, forward_expansion, kernel_size=3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(forward_expansion)\n        self.conv2 = nn.Conv2d(forward_expansion, out_channels, kernel_size=3, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = nn.ReLU()(out)\n        out = nn.Dropout(0.1)(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = nn.ReLU()(out)\n        out = nn.Dropout(0.1)(out)\n        return out\n\nclass BigUNet(nn.Module):\n    def __init__(self, in_channels=12, out_channels=1):\n        super(BigUNet, self).__init__()\n\n        # Downward pass\n\n        self.first = nn.Sequential(\n            nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n        )\n\n        self.down1 = nn.Sequential(\n            BigBasicBlock(64, 64, 128),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        self.down2 = nn.Sequential(\n            BigBasicBlock(128, 128, 256),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        self.down3 = nn.Sequential(\n            BigBasicBlock(256, 256, 512),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n\n        # Bottom block\n        self.bottom = BigBasicBlock(512, 512, 512)\n\n        # Upward pass\n        self.up3 = nn.Sequential(\n            nn.ConvTranspose2d(512+512, 256, kernel_size=2, stride=2),\n            BigBasicBlock(256, 256, 256),\n        )\n        self.up2 = nn.Sequential(\n            nn.ConvTranspose2d(256 + 256, 128, kernel_size=2, stride=2),\n            BigBasicBlock(128, 128, 128),\n        )\n        self.up1 = nn.Sequential(\n            nn.ConvTranspose2d(128 + 128, 64, kernel_size=2, stride=2),\n            nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),\n        )\n\n        self.last = nn.Sequential(\n            nn.Conv2d(32 + in_channels, 16, kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(16, 8, kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(8, 4, kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(4, 2, kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(2, 1, kernel_size=3, stride=1, padding=1)  \n        )\n\n    def forward(self, x):\n        # Downward pass\n        x_initial = self.first(x)\n        x1 = self.down1(x_initial)\n        x2 = self.down2(x1)\n        x3 = self.down3(x2)\n\n        # Bottom block\n        bottom = self.bottom(x3)\n\n        # Upward pass\n        y3 = self.up3(torch.cat((bottom, x3), dim=1))\n        y2 = self.up2(torch.cat((y3, x2), dim=1))\n        y1 = self.up1(torch.cat((y2, x1), dim=1))\n        \n        # Concatenate input layer\n        y_concat = torch.cat((y1, x), dim=1)\n        \n        y = self.last(y_concat)\n        y = nn.ReLU()(y)\n\n        return y\n\n","metadata":{"id":"KTTDlkFpiGnV","execution":{"iopub.status.busy":"2023-03-21T10:43:49.837096Z","iopub.execute_input":"2023-03-21T10:43:49.837483Z","iopub.status.idle":"2023-03-21T10:43:49.857222Z","shell.execute_reply.started":"2023-03-21T10:43:49.837456Z","shell.execute_reply":"2023-03-21T10:43:49.856075Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"# Create a training loop\ndef train(model, dataloader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    for i, data in enumerate(dataloader, 0):\n        inputs, labels = data['input_image'].to(device), data['dose'].to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    return running_loss / (i + 1)\n\n# Create a validation loop\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    with torch.no_grad():\n        for i, data in enumerate(dataloader, 0):\n            inputs, labels = data['input_image'].to(device), data['dose'].to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item()\n    return running_loss / (i + 1)\n","metadata":{"id":"wCTO3vKnLCPd","execution":{"iopub.status.busy":"2023-03-21T10:43:49.858572Z","iopub.execute_input":"2023-03-21T10:43:49.858993Z","iopub.status.idle":"2023-03-21T10:43:49.873004Z","shell.execute_reply.started":"2023-03-21T10:43:49.858954Z","shell.execute_reply":"2023-03-21T10:43:49.871891Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# Train the model and evaluate its performance on the validation set\nnum_epochs = 15\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nmodel = BigUNet().to(device)\ncriterion = nn.L1Loss()\noptimizer = optim.Adam(model.parameters(), lr=0.00001)\n\ntrain_loss_list = []\nval_loss_list = []\n\nfor epoch in range(num_epochs):\n    train_loss = train(model, train_dataloader, criterion, optimizer, device)\n    val_loss = validate(model, val_dataloader, criterion, device)\n    print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n    train_loss_list.append(train_loss)\n    val_loss_list.append(val_loss)\n\n# Save the trained model\ntorch.save(model.state_dict(), 'trained_model.pth')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"41jaPhkTLCPd","outputId":"2f0163c3-0e46-4f0d-8d96-ff1aeef982e1","execution":{"iopub.status.busy":"2023-03-21T10:43:49.874418Z","iopub.execute_input":"2023-03-21T10:43:49.874899Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"cuda\nEpoch 1/15, Train Loss: 2.8364, Val Loss: 2.2468\nEpoch 2/15, Train Loss: 2.0798, Val Loss: 1.9816\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Epoch 1/15, Train Loss: 2.3127, Val Loss: 1.7891\nEpoch 2/15, Train Loss: 1.3737, Val Loss: 1.1563\nEpoch 3/15, Train Loss: 1.1337, Val Loss: 1.1161\nEpoch 4/15, Train Loss: 1.0713, Val Loss: 1.0499\nEpoch 5/15, Train Loss: 1.0433, Val Loss: 1.1620\nEpoch 6/15, Train Loss: 1.0064, Val Loss: 0.9521\nEpoch 7/15, Train Loss: 0.9911, Val Loss: 1.0015\nEpoch 8/15, Train Loss: 0.9615, Val Loss: 1.1773\nEpoch 9/15, Train Loss: 0.9416, Val Loss: 1.1358\nEpoch 10/15, Train Loss: 0.9284, Val Loss: 0.9237\nEpoch 11/15, Train Loss: 0.9069, Val Loss: 0.9929\nEpoch 12/15, Train Loss: 0.8920, Val Loss: 0.8746\nEpoch 13/15, Train Loss: 0.8807, Val Loss: 0.9296\nEpoch 14/15, Train Loss: 0.8664, Val Loss: 0.9162\nEpoch 15/15, Train Loss: 0.8530, Val Loss: 0.8629\n","metadata":{"id":"k_kqV8f9k5rc"}},{"cell_type":"markdown","source":"data aug (only normalise)","metadata":{}},{"cell_type":"code","source":"plt.plot(range(num_epochs), train_loss_list, label='Training Loss')\nplt.plot(range(num_epochs), val_loss_list, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show","metadata":{"id":"qfshmoP3lnbs","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(num_epochs), train_loss_list, label='Training Loss')\nplt.plot(range(num_epochs), val_loss_list, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show\n\n\n","metadata":{"id":"sAely7FDZ_Mv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"BigUnet -> train: val: 0.9933\n\n\nBigUnet with dropout -> train: val: 1.001\n\n","metadata":{"id":"vN7gYQ0bCLJ3"}},{"cell_type":"code","source":"# load the trained model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = UNet().to(device)\n# Load the trained model\nmodel.load_state_dict(torch.load('/content/drive/MyDrive/trained_model.pth'))","metadata":{"id":"FHYyRJM8o4XT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\n# Create a directory to store the predicted dose files\noutput_dir = \"predictions\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Loop through the test dataset and make predictions\nwith torch.no_grad():\n    for idx, data in enumerate(test_dataloader):\n        sample_names = data['sample_name']\n        inputs = data['input_image'].to(device)\n        outputs = model(inputs)\n        \n        batch_outputs = outputs.cpu().numpy()\n        \n        # Save each sample's prediction separately\n        for i, sample_name in enumerate(sample_names):\n            output_file = os.path.join(output_dir, f'{sample_name}.npy')\n            np.save(output_file, batch_outputs[i])\n\n# Create a zip file with all the predicted dose files\nwith zipfile.ZipFile(\"submission.zip\", \"w\") as zf:\n    for file in os.listdir(output_dir):\n        file_path = os.path.join(output_dir, file)\n        zf.write(file_path, arcname=file)\n\n","metadata":{"id":"gnWh1PyMeKb6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass DenseBlock(nn.Module):\n    def __init__(self, in_channels, growth_rate, num_layers, dropout_rate, l2):\n        super(DenseBlock, self).__init__()\n        self.layers = nn.ModuleList([\n            nn.Sequential(\n                nn.BatchNorm2d(in_channels + growth_rate * i),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(in_channels + growth_rate * i, growth_rate, 3, padding=1, bias=False),\n                nn.Dropout(dropout_rate) if dropout_rate else nn.Identity()\n            )\n            for i in range(num_layers)\n        ])\n    \n    def forward(self, x):\n        for layer in self.layers:\n            out = layer(x)\n            x = torch.cat([x, out], dim=1)\n        return x\n\nclass TransitionDown(nn.Module):\n    def __init__(self, in_channels, out_channels, dropout_rate):\n        super(TransitionDown, self).__init__()\n        self.layers = nn.Sequential(\n            nn.BatchNorm2d(in_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n            nn.Dropout(dropout_rate) if dropout_rate else nn.Identity(),\n            nn.AvgPool2d(2)\n        )\n\n    def forward(self, x):\n        return self.layers(x)\n\nclass DenseUNet(nn.Module):\n    def __init__(self, input_shape, dropout_rate=None, l2=0.00000001, activation='relu', lr=0.0001, print_summary=False):\n        super(DenseUNet, self).__init__()\n\n        self.encoder = nn.Sequential(\n            nn.Conv2d(input_shape[2], 32, 3, padding=1, bias=False),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True)\n        )\n\n        growth_rates = [8, 16, 32, 64]\n        self.dense_blocks = nn.ModuleList([DenseBlock(32 + sum(growth_rates[:i]), growth_rate, 4, dropout_rate, l2) for i, growth_rate in enumerate(growth_rates)])\n        self.transition_downs = nn.ModuleList([TransitionDown(32 + sum(growth_rates[:i + 1]), 32 + sum(growth_rates[:i + 1]), dropout_rate) for i in range(len(growth_rates) - 1)])\n\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(800, 512, 3, stride=2, padding=1, output_padding=1, bias=False),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 256, 1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            DenseBlock(256, 64, 4, dropout_rate, l2),\n            nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 128, 1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            DenseBlock(128, 32, 4, dropout_rate, l2),\n            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 64, 1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            DenseBlock(64, 16, 4, dropout_rate, l2),\n            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 32, 1, bias=False),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            DenseBlock(32, 8, 4, dropout_rate, l2)\n            )\n\n        self.output = nn.Conv2d(80, 1, 1, bias=True)\n            \n        self.print_summary = print_summary\n\n        def forward(self, x):\n            x1 = self.encoder(x)\n            x = x1\n\n            for dense_block, transition_down in zip(self.dense_blocks[:-1], self.transition_downs):\n                x = dense_block(x)\n                x = transition_down(x)\n\n            x = self.dense_blocks[-1](x)\n\n            x = self.decoder(x)\n            x = torch.cat([x, x1], dim=1)\n            x = self.output(x)\n            \n            return x\n\n","metadata":{"id":"VGXygExvLCPg","trusted":true},"execution_count":null,"outputs":[]}]}