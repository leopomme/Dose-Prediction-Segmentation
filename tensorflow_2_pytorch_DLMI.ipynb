{
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leopomme/Dose-Prediction-Segmentation/blob/main/tensorflow_2_pytorch_DLMI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wjwEL6iD0ZXt",
        "outputId": "c720bb2a-1546-40ae-b451-fb2e3e6724f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50\n",
        "from keras.layers.convolutional import Conv2D\n",
        "import keras\n",
        "import collections\n",
        "\n",
        "inputpath = '/content/drive/MyDrive/RadImageNet-ResNet50_notop.h5'\n",
        "outpath = '/content/drive/MyDrive/RadImageNet-ResNet50_notop_torch.pth'\n",
        "testimg = '/content/drive/MyDrive/img_test_drive.png'\n",
        "\n",
        "def simple_test(net):\n",
        "    img = Image.open(testimg).convert('L')  # Change 'RGB' to 'L' for grayscale\n",
        "\n",
        "    trans_data = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    img = trans_data(img).unsqueeze(0)\n",
        "    img_rgb = img.repeat(1, 3, 1, 1)  # Repeat the single channel 3 times to create an RGB image with dimensions [N, C, H, W] = [1, 3, H, W]\n",
        "    print(img_rgb.shape)\n",
        "    out = net(img_rgb)\n",
        "    return out.squeeze(0)[0]\n",
        "\n",
        "\n",
        "def keras_to_pyt(km, pm=None):\n",
        "  weight_dict = dict()\n",
        "  \n",
        "  for layer in km.layers:\n",
        "      layer_name = layer.get_config()['name']\n",
        "      \n",
        "      if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "          weight_dict[layer_name + '.weight'] = np.transpose(layer.get_weights()[0], (3, 2, 0, 1)) if len(layer.get_weights()[0].shape) == 4 else np.transpose(layer.get_weights()[0], (1, 0))\n",
        "          weight_dict[layer_name + '.bias'] = layer.get_weights()[1]\n",
        "      elif isinstance(layer, keras.layers.BatchNormalization):\n",
        "          weight_dict[layer_name + '.weight'] = layer.get_weights()[0]\n",
        "          weight_dict[layer_name + '.bias'] = layer.get_weights()[1]\n",
        "          weight_dict[layer_name + '.running_mean'] = layer.get_weights()[2]\n",
        "          weight_dict[layer_name + '.running_var'] = layer.get_weights()[3]\n",
        "  \n",
        "  if pm:\n",
        "      pyt_state_dict = pm.state_dict()\n",
        "      \n",
        "      for key in pyt_state_dict.keys():\n",
        "          if key in weight_dict:\n",
        "              pyt_state_dict[key] = torch.from_numpy(weight_dict[key])\n",
        "      \n",
        "      pm.load_state_dict(pyt_state_dict)\n",
        "      return pm\n",
        "  \n",
        "  return weight_dict\n",
        "\n",
        "\n",
        "net = resnet50(num_classes=1)\n",
        "\n",
        "out = simple_test(net)\n",
        "print('before output is', out)\n",
        "\n",
        "tf_keras_model = tf.keras.models.load_model(inputpath)\n",
        "weights = keras_to_pyt(tf_keras_model, net)\n",
        "\n",
        "out = simple_test(net)\n",
        "print('after output is', out)\n",
        "\n",
        "torch.save(net.state_dict(), outpath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcBied6Bvuo6",
        "outputId": "d5ebca85-59b0-48a1-de3f-de3a0dbe8a94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 224, 224])\n",
            "before output is tensor(-0.1847, grad_fn=<SelectBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 224, 224])\n",
            "after output is tensor(-0.1847, grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tf2onnx -qq\n",
        "! pip install onnx2torch -qq"
      ],
      "metadata": {
        "id": "oITQan5r5fzE",
        "outputId": "b9da4c27-3e36-4a41-b700-aaac8bab0e2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.3/442.3 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 KB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "# import onnxruntime\n",
        "\n",
        "from sklearn.metrics import mean_squared_error as MSE"
      ],
      "metadata": {
        "id": "Y-tVX3pI5iby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the tensorflow radimagenet model\n",
        "model_name = \"RadImageNet-ResNet50_notop\"\n",
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/RadImageNet-ResNet50_notop.h5\")\n",
        "model.save(os.path.join(\"/content/drive/MyDrive\", model_name))"
      ],
      "metadata": {
        "id": "mzUKYD7c5peu",
        "outputId": "22aff9f1-8ec1-4f97-fe3e-982ff2ebc73d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict using tf radimagenet\n",
        "a = np.ones((1, 224, 224, 3))\n",
        "a = tf.convert_to_tensor(a, dtype=tf.float32)\n",
        "tf_out = model.predict(a)\n",
        "tf_out = np.array(tf_out)"
      ],
      "metadata": {
        "id": "gxEMd-uAecAT",
        "outputId": "456d356a-5bf3-48b9-b95e-55cb299eefd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert tensorflow model to onnx model\n",
        "! python -m tf2onnx.convert --opset 13 \\\n",
        "    --saved-model {os.path.join(\"/content/drive/MyDrive\", model_name)} \\\n",
        "    --output  {os.path.join(\"/content/drive/MyDrive\", model_name + \".onnx\")}"
      ],
      "metadata": {
        "id": "oSlUJlmD533K",
        "outputId": "7a94a737-612f-4fd1-a543-1f0dc087ed4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-22 13:24:21.236089: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-22 13:24:21.236217: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-22 13:24:21.236243: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/usr/lib/python3.9/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "2023-03-22 13:24:23,077 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
            "2023-03-22 13:24:37,359 - INFO - Signatures found in model: [serving_default].\n",
            "2023-03-22 13:24:37,359 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
            "2023-03-22 13:24:37,361 - INFO - Output names: ['conv5_block3_out']\n",
            "2023-03-22 13:24:47,844 - INFO - Using tensorflow=2.11.0, onnx=1.13.1, tf2onnx=1.13.0/2c1db5\n",
            "2023-03-22 13:24:47,844 - INFO - Using opset <onnx, 13>\n",
            "2023-03-22 13:24:48,323 - INFO - Computed 0 values for constant folding\n",
            "2023-03-22 13:24:49,364 - INFO - Optimizing ONNX model\n",
            "2023-03-22 13:24:51,463 - INFO - After optimization: Add -1 (17->16), BatchNormalization -53 (53->0), Const -213 (320->107), Identity -2 (2->0), Transpose -212 (214->2)\n",
            "2023-03-22 13:24:52,812 - INFO - \n",
            "2023-03-22 13:24:52,812 - INFO - Successfully converted TensorFlow model /content/drive/MyDrive/RadImageNet-ResNet50_notop to ONNX\n",
            "2023-03-22 13:24:52,812 - INFO - Model inputs: ['input_2']\n",
            "2023-03-22 13:24:52,813 - INFO - Model outputs: ['conv5_block3_out']\n",
            "2023-03-22 13:24:52,813 - INFO - ONNX model is saved at /content/drive/MyDrive/RadImageNet-ResNet50_notop.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert onnx to pytorch model\n",
        "import torch\n",
        "from onnx2torch import convert\n",
        "\n",
        "onnx_model_path = os.path.join(\"/content/drive/MyDrive\", model_name + \".onnx\")\n",
        "torch_model = convert(onnx_model_path)\n",
        "torch.save(torch_model.state_dict(), model_name + \".pth\")"
      ],
      "metadata": {
        "id": "1EnOecDB56Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict using pytorch radimagenet\n",
        "a = np.ones((1, 224, 224, 3))\n",
        "a = torch.tensor(a).float()\n",
        "torch_out = torch_model(a)\n",
        "torch_out = torch_out.detach().numpy()"
      ],
      "metadata": {
        "id": "MEbRKq8i5_q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare the outputs\n",
        "print(MSE(tf_out.reshape(-1), torch_out.reshape(-1)))"
      ],
      "metadata": {
        "id": "HLBQt96C6UpJ",
        "outputId": "9da40f90-aab3-495d-a97b-07b27a918402",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6138929e-12\n"
          ]
        }
      ]
    }
  ]
}